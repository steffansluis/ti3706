\paragraph{Performance Counters}``Performance counters are used to measure events that occur events that occur duing program execution.''\cite{PC} Think of events like the number of instructions, loads, bandwidth or the number of executed cycles.

``The goal of analyzing performance counters is to detect if a performance regression has occured, where the performance regression has occured, and what causes the regression.'' \cite{nguyen2012using}

To detect if performance regression occurs, two tests will be run: a target run and a baseline run. The target run is the new test run, where the baseline run is a good past run. On both tests equivalent performance counters can be used as input to detect if performance regression has occured by comparing the output of the tests. Comparing the output of the tests is a big challenge, especially in big complex software systems.

If it is known that performance regression has occured, the next problem is to detect where the performance regression has occured. Big software systems consist of many types of components, and each component may have many instances. Detecting where the perfomance regression has occured is very difficult, because there are many performance counters for each instance of each component. This can be very time consuming.

After determining the location of the performance regression, the reason of the performance regression needs to be determined. ``Understanding the kind of problem usually requires static analysis of source code.'' \cite{nguyen2012using}

The fact that performance counters are often used by application developers shows that performance counters are very useful. However, performance counters arn't that accurate. Tests with different interfaces (perfmon2 and perfctr) and different counter configurations (user and user+kernel) show that for the combination of the perfmon2 interface and user+kernel configuration the measurement error increases as the number of registers increases as well. \cite{AccuracyPerformanceCounter}
Also, the type of infrastructure is very dependent. The measurement error reduces a lot when a low-level infrastructure is used, instead of a high-level infrastructure.
On top of that, for the user+kernel mode the measurement error gets bigger if the duration of the benchmark gets longer. \cite{AccuracyPerformanceCounter} So to make the measurement error smaller, less loop iterations should be used.  The infrastructure doesn't have influence. For the user mode the duration of the benchmark doesn't matter. This is because of interrupts, that only occur in kernel event counts. More interrupt-related instructions will include if the duration of a measurement takes longer.
